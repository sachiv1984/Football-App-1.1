# src/services/ai/backtest_processor.py

import pandas as pd
import numpy as np
import logging

logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

def load_raw_data() -> tuple[pd.DataFrame, pd.DataFrame]:
    """Loads the raw Parquet files generated by data_loader.py and standardizes date formats."""
    logger.info("Loading raw Parquet files...")
    
    try:
        # Files are downloaded by GitHub Actions into the working directory
        df_player = pd.read_parquet("player_data_raw.parquet")
        df_team_def = pd.read_parquet("team_def_data_raw.parquet")
        
        # ðŸŽ¯ FIX: Ensure match_date is a clean datetime object (time set to midnight) for reliable merging
        df_player['match_date'] = pd.to_datetime(df_player['match_date']).dt.normalize()
        df_team_def['match_date'] = pd.to_datetime(df_team_def['match_date']).dt.normalize()
        
        logger.info(f"Loaded player data shape: {df_player.shape}")
        logger.info(f"Loaded team defense data shape: {df_team_def.shape}")
        return df_player, df_team_def
    except FileNotFoundError as e:
        logger.error(f"Missing input file. Did the data_loader job fail? {e}")
        exit(1)


def determine_opponent(df_player: pd.DataFrame) -> pd.DataFrame:
    """
    Extracts the opponent team name by comparing the player's team_name 
    against the home_team and away_team columns.
    """
    logger.info("Determining opponent teams using home/away columns...")
    
    # Define the logic using NumPy's select for fast, vectorized conditional assignment
    conditions = [
        # Condition 1: If player's team is the HOME team, the opponent is the AWAY team
        (df_player['team_name'] == df_player['home_team']),
        # Condition 2: If player's team is the AWAY team, the opponent is the HOME team
        (df_player['team_name'] == df_player['away_team'])
    ]
    
    choices = [
        df_player['away_team'], # Result for Condition 1
        df_player['home_team']  # Result for Condition 2
    ]
    
    df_player['opponent'] = np.select(conditions, choices, default=np.nan)
    
    # Clean up any records where the player's team name didn't match either home or away
    df_player.dropna(subset=['opponent'], inplace=True)
    
    logger.info(f"Successfully determined opponents for {len(df_player)} records.")
    
    # Clean up columns that are no longer needed for the final feature set
    df_player = df_player.drop(columns=['home_team', 'away_team'])
    
    return df_player


def calculate_opponent_factors(df_player: pd.DataFrame, df_team_def: pd.DataFrame) -> pd.DataFrame:
    """
    Calculates the rolling average of opponent defensive stats (O-Factor) 
    by merging on the calculated 'opponent' and 'match_date'.
    """
    logger.info("Calculating rolling opponent defensive factors (O-Factors)...")
    
    # 1. Prepare opponent defense data
    # Rename 'team_name' to 'opponent' for the merge
    df_opp_def = df_team_def.rename(columns={'team_name': 'opponent'})
    
    # 2. Merge player stats with the opponent's historical defense stats
    df_merged = pd.merge(
        df_player,
        # Merge on: [The Opponent's Name, The Match Date]
        df_opp_def[['opponent', 'match_date', 'sot_conceded', 'tackles_att_3rd']],
        on=['opponent', 'match_date'],
        how='left',
        # Note: suffixes are only applied when columns conflict (e.g., if df_player had 'sot_conceded')
        # However, we rely on the existence of these columns for the next step.
        suffixes=('_player', '_opp_raw') 
    )
    
    # 3. Defensive check and column creation (The core fix for the KeyError)
    
    raw_sot_col = 'sot_conceded_opp_raw'
    raw_tackle_col = 'tackles_att_3rd_opp_raw'

    # If the merge was successful, the raw columns are named as expected.
    # If the merge failed (no matches), the columns from the right DataFrame are NOT included.
    if raw_sot_col not in df_merged.columns:
        logger.warning(f"Merge failed. Data for '{raw_sot_col}' not found. Filling with NaN.")
        # If the merge failed, the columns from the right side were not appended. 
        # Append them manually as NaN to prevent the next step from crashing.
        df_merged[raw_sot_col] = np.nan
        df_merged[raw_tackle_col] = np.nan
        # We assume the user has correctly named the columns in the team defense DF
        # to sot_conceded and tackles_att_3rd after the loader's merges.
    else:
        # Check if the columns were appended without the suffix (meaning they didn't conflict)
        # This is a safety check for a different merge scenario.
        if raw_sot_col not in df_merged.columns and 'sot_conceded' in df_merged.columns:
            df_merged.rename(columns={'sot_conceded': raw_sot_col, 'tackles_att_3rd': raw_tackle_col}, inplace=True)


    # 4. Calculate Rolling Average of Opponent Stats (AVOID DATA LEAKAGE)
    
    # Group by the Opponent and apply a rolling window of 5 matches
    for col in [raw_sot_col, raw_tackle_col]:
        new_col_name = col.replace('_raw', '_MA5')
        
        df_merged[new_col_name] = (
            df_merged
            .groupby('opponent')[col]
            # closed='left' ensures the window excludes the current row's data (no data leakage)
            .transform(lambda x: x.rolling(window=5, min_periods=1, closed='left').mean())
        )
    
    # Drop the raw columns after calculation
    df_merged = df_merged.drop(columns=[raw_sot_col, raw_tackle_col])
    
    logger.info("O-Factors calculated and ready for the final backtesting step.")
    return df_merged


if __name__ == '__main__':
    df_player_raw, df_team_def_raw = load_raw_data()
    
    if df_player_raw.empty or df_team_def_raw.empty:
        logger.error("Cannot proceed with processing: Raw data is empty.")
        exit(1)
    
    # Step 1: Determine the Opponent Name
    df_player_with_opp = determine_opponent(df_player_raw)
    
    # Step 2: Merge Data and Calculate Rolling Opponent Factors
    df_final_features = calculate_opponent_factors(df_player_with_opp, df_team_def_raw)
    
    # Step 3: Save the final feature set for the actual backtesting script
    output_file = "final_feature_set.parquet"
    df_final_features.to_parquet(output_file, index=False)
    logger.info(f"Process complete. Final feature set saved to {output_file} with shape: {df_final_features.shape}")
