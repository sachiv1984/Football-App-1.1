name: Backtest SOT Model

on:
  # This section is updated to only include workflow_dispatch,
  # which allows for manual triggering from the GitHub Actions UI.
  workflow_dispatch:

jobs:
  load_data:
    name: 1. Load Data from Supabase
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Set up Python Environment
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: pip install -r requirements.txt
        
    - name: Execute Data Loader and Save Files ðŸ’¾
      env:
        # NOTE: Ensure these secrets are configured in your repo settings
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      run: |
        echo "Running data_loader.py to pull data from Supabase..."
        python src/services/ai/data_loader.py
        
    - name: Upload Data Artifacts ðŸ“¤
      uses: actions/upload-artifact@v4
      with:
        name: raw-backtest-data
        path: |
          player_data_raw.parquet
          team_def_data_raw.parquet

# ---------------------------------------------------------------------

  process_data:
    name: 2. Feature Engineer (O-Factors)
    needs: load_data
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python Environment
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: pip install -r requirements.txt
      
    - name: Download Raw Data Artifacts ðŸ“¥
      uses: actions/download-artifact@v4
      with:
        name: raw-backtest-data
        
    - name: Run Backtest Processor Script (O-Factors)
      run: |
        echo "Running backtest_processor.py to merge and calculate O-factors..."
        python src/services/ai/backtest_processor.py 
        
    - name: Upload O-Factor Data ðŸ“¤
      uses: actions/upload-artifact@v4
      with:
        name: final-feature-set-o-factors
        path: final_feature_set.parquet

# ---------------------------------------------------------------------

  analyze_and_scale:
    name: 3. P-Factors, Correlation, Scaling, and Backtest
    needs: process_data
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python Environment
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: pip install -r requirements.txt
      
    - name: Download O-Factor Data ðŸ“¥
      uses: actions/download-artifact@v4
      with:
        name: final-feature-set-o-factors
        
    - name: Run P-Factor Engineer Script
      run: |
        echo "Running player_factor_engineer.py to calculate P-Factors..."
        python src/services/ai/player_factor_engineer.py
        
    - name: Run Correlation Analysis (Full Feature Set)
      run: |
        echo "Running correlation_analysis.py..."
        python src/services/ai/correlation_analysis.py 
        
    - name: Run Feature Scaling Script (Player Filtering and Standardization)
      # Filters out non-offensive players and standardizes features
      run: |
        echo "Running feature_scaling.py to filter and standardize data..."
        python src/services/ai/feature_scaling.py

    - name: Run Backtesting Model and Save Model
      # Runs the Poisson regression, evaluates performance, and saves the model (poisson_model.pkl)
      run: |
        echo "Running backtest_model.py to evaluate model and save pkl..."
        python src/services/ai/backtest_model.py

    - name: Run Prediction Service Simulation
      # Tests that the saved model can be loaded and used for a live prediction
      run: |
        echo "Running prediction_service.py to test deployment readiness..."
        python src/services/ai/prediction_service.py
        
    - name: Upload Final Model Artifacts ðŸ“¤
      uses: actions/upload-artifact@v4
      with:
        name: final-model-artifacts
        # Uploads the scaled data and the trained model file for deployment
        path: |
          final_feature_set_scaled.parquet
          poisson_model.pkl